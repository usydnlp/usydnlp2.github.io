# Workshop on Toxicity Detection in Games

## About Workshop

**Toxicity Dual Detection Workshop** will be held within the The Web Conference [(WWW)](https://www2022.thewebconf.org/) between 25th - 29th, 2022. The workshop date will be released in Dec 2021.

### Workshop Description

As the popularity of multi-player online games has grown, the phenomenon of in-game toxic behaviour has taken root within them. Like other social platforms, toxic behaviour is strongly present in recent online games and is problematic to the gaming industry. These have the effect of loss of enjoyment for players which can lead to loss of player base, and longer term self-esteem effects. Fast detection of such behaviour can enable mitigation strategies to been acted to thwart the toxic situations.

The goal of the workshop is to bring together researchers and practitioners from academia and industry to engage in a discussion about identifying and combating such toxicity behaviour. The workshop consists on (1) a series of invited talks by reputed members of the community of online toxicity from both academia and industry, (2) a call-for-papers for contributed talks, (3) a shared task with leaderboard challenges for CONDA toxicity dataset, and (4) a multidisciplinary panel discussion.

In this workshop, 4 industry leads (from Thales, Microsoft, Appen, and Blizzard) and 3 academic experts (from The University of HongKong (HKU), University of New South Wales (UNSW), and Sydney Health Literacy Lab from the University of Sydney) will expose multidisciplinary challenges, solutions, and ongoing research in gaming areas.

Topics of interest include, but are not limited to:

- Multimodal Toxicity Detection in Games
- Natural Language Understanding and Generation of Dialogue in Games
- In-game Chat Content Modelling
- Evaluation of games for NLP
- Applications of Toxicity Detection in Games
- Gamer Behavioral-based Detection
- Bias in Toxicity Detection Systems in Games
- Ethical and Privacy Concerns related to Games

To promote the research and practice on Toxicity Detection in Games, we held a **CONDA Toxicity Dual Detection Challenge** based on the CONDA dataset (accepted by ACL-IJCNLP 2021) from December 2021 to March 2022. This competition provided a good testbed for participants to develop better toxicity detection systems to improve the future reading experience of millions of users.


## CONDA Dataset 

Traditional toxicity detection models have focused on the single utterance level without deeper understanding of context. The CONDA dataset is to detect in-game toxic language, **enabling joint intent classification and slot filling analysis**, which is a core task in Natural Language Understanding (NLU). The dataset consists of 45K utterances from 12K conversations from the chat logs of 1.9K completed the _Defense of the Ancients 2 (Dota 2)_ matches. Dota 2 is a multiplayer online game where teams of five players attempt to destroy their opponents' ancient structure.
- Paper [Link](https://arxiv.org/abs/2106.06213)
- Github [Link](https://github.com/usydnlp/CONDA)
- Challenge [Link](https://usydnlp2.github.io/challenge) : CONDA 1.0 (in 2022), CONDA 2.0 (in 2023 - later)
- Competition [Link](https://competitions.codalab.org/)


## Speakers
- Industry: Thales, Microsoft, Blizzard
- Keynote Speaker: Medical Doctor(HKU), Blackdog Institute (UNSW), Appen, Sydney Health Literacy Group (Australian Gov)

To be announced (TBA)


## Schedule
To be announced (TBA)


## Call for Papers
To be announced (TBA)


## Organisers
To be announced (TBA)

To contact the organisers, send us an e-mail to [caren.han@sydney.edu.au](mailto:caren.han@sydney.edu.au)


